---
title: "FINAL-QDA"
author: "Noah Glosson"
date: "2025-06-10"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(MASS)
library(caret)
library(pROC)
library(knitr)

# Load Data
df_EDA <- read.csv("df_EDA.csv", header = TRUE)
df_PCA <- read.csv("df_PCA.csv", header = TRUE)
df_PCA$diabetes <- as.factor(df_EDA$diabetes)
df_EDA$diabetes <- as.factor(df_EDA$diabetes)

#Splitting our data up
set.seed(123)
train_index <- createDataPartition(df_PCA$diabetes, p = 0.6, list = FALSE)
train_pca <- df_PCA[train_index, ]
test_pca  <- df_PCA[-train_index, ]
train_eda <- df_EDA[train_index, ]
test_eda  <- df_EDA[-train_index, ]

#QDA Models and predictions
qda_pca <- qda(diabetes ~ ., data = train_pca)
qda_eda <- qda(diabetes ~ ., data = train_eda)
qda_pca_pred <- predict(qda_pca, newdata = test_pca)
qda_eda_pred <- predict(qda_eda, newdata = test_eda)

#Factoring
conf_pca <- confusionMatrix(factor(qda_pca_pred$class, levels = c("neg", "pos")),
                            factor(test_pca$diabetes, levels = c("neg", "pos")))
conf_eda <- confusionMatrix(factor(qda_eda_pred$class, levels = c("neg", "pos")),
                            factor(test_eda$diabetes, levels = c("neg", "pos")))

#Metrics
metrics_df <- data.frame(
  Model = c("PCA QDA", "EDA QDA"),
  Accuracy = c(conf_pca$overall["Accuracy"], conf_eda$overall["Accuracy"]),
  Recall = c(conf_pca$byClass["Sensitivity"], conf_eda$byClass["Sensitivity"]),
  Precision = c(conf_pca$byClass["Pos Pred Value"], conf_eda$byClass["Pos Pred Value"]),
  Specificity = c(conf_pca$byClass["Specificity"], conf_eda$byClass["Specificity"]),
  F1 = c(
    2 * ((conf_pca$byClass["Pos Pred Value"] * conf_pca$byClass["Sensitivity"]) /
           (conf_pca$byClass["Pos Pred Value"] + conf_pca$byClass["Sensitivity"])),
    2 * ((conf_eda$byClass["Pos Pred Value"] * conf_eda$byClass["Sensitivity"]) /
           (conf_eda$byClass["Pos Pred Value"] + conf_eda$byClass["Sensitivity"]))
  )
)

conf_pca
conf_eda
kable(metrics_df, digits = 4, caption = "QDA Performance Comparison: PCA vs EDA")

```

```{r}

roc_pca <- roc(test_pca$diabetes, qda_pca_pred$posterior[, "pos"])
plot(roc_pca, col = "darkred", main = "PCA ROC Curve", lwd = 2)
legend("bottomright", legend = "PCA", col = "darkred", lwd = 2)

roc_eda <- roc(test_eda$diabetes, qda_eda_pred$posterior[, "pos"])
plot(roc_eda, col = "blue", main = "EDA ROC Curve", lwd = 2)
legend("bottomright", legend = "EDA", col = "blue", lwd = 2)

```

Accuracy Results PCA
```{r}
accuracy_results <- c()
conf_matrices <- list()
for (k in 2:7) {
  temp_df <- df_PCA[, 1:k]
  temp_df$diabetes <- df_PCA$diabetes

  set.seed(123)
  train_index <- createDataPartition(temp_df$diabetes, p = 0.6, list = FALSE)
  train <- temp_df[train_index, ]
  test <- temp_df[-train_index, ]

  qda_model <- qda(diabetes ~ ., data = train)
  pred <- predict(qda_model, newdata = test)$class
  cm <- table(Predicted = pred, Actual = test$diabetes)
  conf_matrices[[paste0("PC", k)]] <- cm

  acc <- mean(pred == test$diabetes)
  accuracy_results <- c(accuracy_results, acc)
}

plot(2:7, accuracy_results, type = "b",
     xlab = "# of Principal Components",
     ylab = "QDA Test Accuracy",
     main = "QDA Accuracy by # of PCA Components")
best_k <- which.max(accuracy_results) + 1
cat("Best PCA model used", best_k, "components with accuracy:",
    round(accuracy_results[best_k - 1], 4), "\n")

```




```{r}
# Accuracy vs. EDA Features
all_vars <- names(df_EDA)[names(df_EDA) != "diabetes"]
accuracy_results_eda <- c()
conf_matrices_eda <- list()

for (k in 2:8) {
  selected_vars <- all_vars[1:k]
  temp_df <- df_EDA[, c(selected_vars, "diabetes")]

  set.seed(123)
  train_index <- createDataPartition(temp_df$diabetes, p = 0.6, list = FALSE)
  train <- temp_df[train_index, ]
  test <- temp_df[-train_index, ]

  qda_model <- qda(diabetes ~ ., data = train)
  pred <- predict(qda_model, newdata = test)$class
  cm <- table(Predicted = pred, Actual = test$diabetes)
  conf_matrices_eda[[paste0("EDA_", k)]] <- cm

  acc <- mean(pred == test$diabetes)
  accuracy_results_eda <- c(accuracy_results_eda, acc)
}

plot(2:8, accuracy_results_eda, type = "b",
     xlab = "# of Original Features",
     ylab = "QDA Test Accuracy",
     main = "QDA Accuracy by # of Original Features")
best_k_eda <- which.max(accuracy_results_eda) + 1
cat("Best EDA model used", best_k_eda, "features with accuracy:",
    round(accuracy_results_eda[best_k_eda - 1], 4), "\n")

```

Checking for Overfitting
```{r}

#We want to check for overfitting with training vs. testing
all_vars <- names(df_EDA)[names(df_EDA) != "diabetes"]
accuracy_results_eda <- c()
train_accuracy_eda <- c()

for (k in 2:8) {
  selected_vars <- all_vars[1:k]
  temp_df <- df_EDA[, c(selected_vars, "diabetes")]

  set.seed(123)
  train_index <- createDataPartition(temp_df$diabetes, p = 0.6, list = FALSE)
  train <- temp_df[train_index, ]
  test <- temp_df[-train_index, ]

  qda_model <- qda(diabetes ~ ., data = train)

  # Train Accuracy
  train_pred <- predict(qda_model, newdata = train)$class
  train_acc <- mean(train_pred == train$diabetes)

  # Test Accuracy
  test_pred <- predict(qda_model, newdata = test)$class
  test_acc <- mean(test_pred == test$diabetes)

  train_accuracy_eda <- c(train_accuracy_eda, train_acc)
  accuracy_results_eda <- c(accuracy_results_eda, test_acc)

  cat("Features:", k, "| Train Accuracy:", round(train_acc, 4), "| Test Accuracy:", round(test_acc, 4), "\n")
}


#PCA Overfit
accuracy_results_pca <- c()
train_accuracy_pca <- c()

for (k in 2:7) {
  temp_df <- df_PCA[, 1:k]
  temp_df$diabetes <- df_PCA$diabetes

  set.seed(123)
  train_index <- createDataPartition(temp_df$diabetes, p = 0.6, list = FALSE)
  train <- temp_df[train_index, ]
  test <- temp_df[-train_index, ]

  qda_model <- qda(diabetes ~ ., data = train)

  #Train and Test Accuracy
  train_pred <- predict(qda_model, newdata = train)$class
  train_acc <- mean(train_pred == train$diabetes)
  test_pred <- predict(qda_model, newdata = test)$class
  test_acc <- mean(test_pred == test$diabetes)

  train_accuracy_pca <- c(train_accuracy_pca, train_acc)
  accuracy_results_pca <- c(accuracy_results_pca, test_acc)

  cat("PCs:", k, "| Train Accuracy:", round(train_acc, 4), "| Test Accuracy:", round(test_acc, 4), "\n")
}


#Confusion Matrix for only 5 components
df_PCA_5 <- df_PCA[, 1:5]
df_PCA_5$diabetes <- df_PCA$diabetes

#Split our data the same way
set.seed(123)
train_index <- createDataPartition(df_PCA_5$diabetes, p = 0.6, list = FALSE)
train_pca_5 <- df_PCA_5[train_index, ]
test_pca_5  <- df_PCA_5[-train_index, ]

#Five components
qda_pca_5 <- qda(diabetes ~ ., data = train_pca_5)
qda_pca_pred_5 <- predict(qda_pca_5, newdata = test_pca_5)

#Confusion Matrix
confusion_5 <- confusionMatrix(factor(qda_pca_pred_5$class, 
                                     levels = c("neg", "pos")),
                              factor(test_pca_5$diabetes, 
                                     levels = c("neg", "pos")))
print(confusion_5)
```
